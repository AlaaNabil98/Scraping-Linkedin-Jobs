{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6724ce2b",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b316ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     \n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from setups import get_local_safe_setup\n",
    "import os\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e3a42",
   "metadata": {},
   "source": [
    "## Login Manually & Save Cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da8a6d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create a new WebDriver instance\\ndriver = webdriver.Chrome()\\n\\n# Navigate to the login page\\ndriver.get(\\'https://www.linkedin.com/login\\')\\n\\n# Manually log in to the website\\ntime.sleep(30)\\n\\npickle.dump( driver.get_cookies() , open(\"cookies.pkl\",\"wb\"))\\n\\n# Close the browser\\ndriver.quit()\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Create a new WebDriver instance\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the login page\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "\n",
    "# Manually log in to the website\n",
    "time.sleep(30)\n",
    "\n",
    "pickle.dump( driver.get_cookies() , open(\"cookies.pkl\",\"wb\"))\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ebc1e",
   "metadata": {},
   "source": [
    "## Login by Cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6acfda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local setup like here: https://gist.github.com/theDestI/aa21a0e721b06a74bd58a0a391d96e8f\n",
    "driver = get_local_safe_setup()\n",
    "\n",
    "# Enter to the site\n",
    "driver.get('https://www.linkedin.com/login');\n",
    "time.sleep(2)\n",
    "\n",
    "# Load the cookies from the file\n",
    "cookies = pickle.load(open(\"cookies.pkl\", \"rb\"))\n",
    "\n",
    "for cookie in cookies:\n",
    "    driver.add_cookie(cookie)\n",
    "\n",
    "# Navigate to a page that requires authentication\n",
    "driver.get('https://www.linkedin.com/jobs/search/?currentJobId=3601104124&geoId=106155005&keywords=data%20analyst&location=Egypt&refresh=true')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77f868",
   "metadata": {},
   "source": [
    "## Get Job offers Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "030c86d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links are being collected now.\n",
      "Collecting the links in the page: 1\n",
      "Collecting the links in the page: 2\n",
      "Collecting the links in the page: 3\n",
      "Collecting the links in the page: 4\n",
      "Collecting the links in the page: 5\n",
      "Collecting the links in the page: 6\n",
      "Collecting the links in the page: 7\n",
      "Collecting the links in the page: 8\n",
      "Found 200 links for job offers\n"
     ]
    }
   ],
   "source": [
    "# Get all links for these offers\n",
    "links = []\n",
    "# Navigate 13 pages\n",
    "print('Links are being collected now.')\n",
    "try: \n",
    "    for page in range(2,10):\n",
    "        time.sleep(2)\n",
    "        jobs_block = driver.find_element(By.CLASS_NAME, 'scaffold-layout__list-container')\n",
    "        jobs_list= jobs_block.find_elements(By.CSS_SELECTOR, '.jobs-search-results__list-item')\n",
    "    \n",
    "        for job in jobs_list:\n",
    "            all_links = job.find_elements(By.TAG_NAME, 'a')\n",
    "            for a in all_links:\n",
    "                if str(a.get_attribute('href')).startswith(\"https://www.linkedin.com/jobs/view\") and a.get_attribute('href') not in links: \n",
    "                    links.append(a.get_attribute('href'))\n",
    "                else:\n",
    "                    pass\n",
    "            # scroll down for each job element\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", job)\n",
    "        \n",
    "        print(f'Collecting the links in the page: {page-1}')\n",
    "        \n",
    "        # go to next page:\n",
    "        driver.find_element(By.XPATH, f\"//button[@aria-label='Page {page}']\").click()\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "except Exception as e:\n",
    "    # Catch the exception and print the error message\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    pass\n",
    "    \n",
    "    \n",
    "print('Found ' + str(len(links)) + ' links for job offers')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc510264",
   "metadata": {},
   "source": [
    "## Scrape Job Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b6b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "offer = 1\n",
    "job_titles = []\n",
    "company_names = []\n",
    "company_locations = []\n",
    "work_methods = []\n",
    "post_dates = []\n",
    "work_times = [] \n",
    "job_desc = []\n",
    "\n",
    "# Visit each link one by one to scrape the information\n",
    "print('Visiting the links and collecting information just started.')\n",
    "\n",
    "\n",
    "for i in range(len(links)):\n",
    "    try:\n",
    "        driver.get(links[i])\n",
    "        #i=i+1\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click See more.\n",
    "        driver.find_element(By.CLASS_NAME, \"artdeco-card__actions\").click()\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Catch the exception and print the error message\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        pass\n",
    "    \n",
    "    # Find the general information of the job offers\n",
    "    contents = driver.find_elements(By.CLASS_NAME, 'p5')\n",
    "    for content in contents:\n",
    "        try:\n",
    "            job_titles.append(content.find_element(By.TAG_NAME, \"h1\").text)\n",
    "        except:\n",
    "            job_titles.append(None)\n",
    "        \n",
    "        try:            \n",
    "            company_names.append(content.find_element(By.CLASS_NAME, \"jobs-unified-top-card__company-name\").text)\n",
    "        except:\n",
    "            company_names.append(None)\n",
    "        \n",
    "        try:\n",
    "            company_locations.append(content.find_element(By.CLASS_NAME, \"jobs-unified-top-card__bullet\").text)\n",
    "        except:\n",
    "            company_locations.append(None)\n",
    "            \n",
    "        try:\n",
    "            work_methods.append(content.find_element(By.CLASS_NAME, \"jobs-unified-top-card__workplace-type\").text)\n",
    "        except:\n",
    "            work_methods.append(None)\n",
    "        \n",
    "        try:            \n",
    "            post_dates.append(content.find_element(By.CLASS_NAME, \"jobs-unified-top-card__posted-date\").text)\n",
    "        except:\n",
    "            post_dates.append(None)\n",
    "        \n",
    "        try:        \n",
    "            work_times.append(content.find_element(By.CLASS_NAME, \"jobs-unified-top-card__job-insight\").text)\n",
    "        except:\n",
    "            work_times.append(None)\n",
    "        \n",
    "        print(f'Scraping the Job Offer {offer} DONE.')\n",
    "        offer+= 1  \n",
    "\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # Scraping the job description\n",
    "    job_description = driver.find_elements(By.CLASS_NAME, 'jobs-description__content')\n",
    "    for description in job_description:\n",
    "        job_text = description.find_element(By.CLASS_NAME, \"jobs-box__html-content\").text\n",
    "        job_desc.append(job_text)\n",
    "                \n",
    "        print(f'Scraping the Job Description {offer}')\n",
    "        time.sleep(2)  \n",
    "\n",
    "df = pd.DataFrame({ 'Job Title': job_titles, 'Company Name': company_names, 'Company Location': company_locations, 'Work Method': work_methods, 'Post Dates': post_dates,\n",
    "               'Work Times': work_times, 'Job Link': links })\n",
    "\n",
    "df.to_csv('job_offers.csv', index=False)\n",
    "\n",
    "\n",
    "# Output job descriptions to txt file\n",
    "with open('job_descriptions.txt', 'w',encoding=\"utf-8\") as f:\n",
    "    for desc in job_desc:\n",
    "        f.write(desc)\n",
    "        f.write('\\n' + '-'*100 + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8fded17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Location</th>\n",
       "      <th>Work Method</th>\n",
       "      <th>Post Dates</th>\n",
       "      <th>Work Times</th>\n",
       "      <th>Job Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud Data Analyst _VOIS</td>\n",
       "      <td>_VOIS</td>\n",
       "      <td>Cairo, Cairo, Egypt</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LV Sales Specialist- Water &amp; Waste water</td>\n",
       "      <td>ABB</td>\n",
       "      <td>Cairo, Cairo, Egypt</td>\n",
       "      <td>On-site</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>System Analyst (Business Analyst)</td>\n",
       "      <td>Agility</td>\n",
       "      <td>Suez, As Suways, Egypt</td>\n",
       "      <td>On-site</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst (Bangkok Based, Relocation Provided)</td>\n",
       "      <td>Agoda</td>\n",
       "      <td>Cairo, Cairo, Egypt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Insights Analyst (Bangkok Based, Relo...</td>\n",
       "      <td>Agoda</td>\n",
       "      <td>Giza, Al Jizah, Egypt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>CBI Associate</td>\n",
       "      <td>UNHCR, the UN Refugee Agency</td>\n",
       "      <td>Cairo, Cairo, Egypt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Full-time · Entry level</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Ultralogistics Transport Planner</td>\n",
       "      <td>Unilever</td>\n",
       "      <td>6th of October, Al Jizah, Egypt</td>\n",
       "      <td>On-site</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>Full-time · Mid-Senior level</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3531284710/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job Title  \\\n",
       "0                             Cloud Data Analyst _VOIS   \n",
       "1             LV Sales Specialist- Water & Waste water   \n",
       "2                    System Analyst (Business Analyst)   \n",
       "3    Data Analyst (Bangkok Based, Relocation Provided)   \n",
       "4    Customer Insights Analyst (Bangkok Based, Relo...   \n",
       "..                                                 ...   \n",
       "145                                      CBI Associate   \n",
       "146                   Ultralogistics Transport Planner   \n",
       "147                                                NaN   \n",
       "148                                                NaN   \n",
       "149                                                NaN   \n",
       "\n",
       "                     Company Name                 Company Location  \\\n",
       "0                           _VOIS              Cairo, Cairo, Egypt   \n",
       "1                             ABB              Cairo, Cairo, Egypt   \n",
       "2                         Agility           Suez, As Suways, Egypt   \n",
       "3                           Agoda              Cairo, Cairo, Egypt   \n",
       "4                           Agoda            Giza, Al Jizah, Egypt   \n",
       "..                            ...                              ...   \n",
       "145  UNHCR, the UN Refugee Agency              Cairo, Cairo, Egypt   \n",
       "146                      Unilever  6th of October, Al Jizah, Egypt   \n",
       "147                           NaN                              NaN   \n",
       "148                           NaN                              NaN   \n",
       "149                           NaN                              NaN   \n",
       "\n",
       "    Work Method  Post Dates                    Work Times  \\\n",
       "0        Hybrid  5 days ago                     Full-time   \n",
       "1       On-site   1 day ago                     Full-time   \n",
       "2       On-site  1 week ago         Full-time · Associate   \n",
       "3           NaN  3 days ago         Full-time · Associate   \n",
       "4           NaN  3 days ago         Full-time · Associate   \n",
       "..          ...         ...                           ...   \n",
       "145         NaN  1 week ago       Full-time · Entry level   \n",
       "146     On-site  4 days ago  Full-time · Mid-Senior level   \n",
       "147         NaN         NaN                           NaN   \n",
       "148         NaN         NaN                           NaN   \n",
       "149         NaN         NaN                           NaN   \n",
       "\n",
       "                                              Job Link  \n",
       "0    https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "1    https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "2    https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "3    https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "4    https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "..                                                 ...  \n",
       "145  https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "146  https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "147  https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "148  https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "149  https://www.linkedin.com/jobs/view/3531284710/...  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print Results\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a64e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
